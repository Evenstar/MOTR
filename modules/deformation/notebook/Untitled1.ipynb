{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(__doc__)\n",
      "\n",
      "from time import time\n",
      "import numpy as np\n",
      "import pylab as pl\n",
      "import scipy.io\n",
      "from sklearn import metrics\n",
      "from sklearn.cluster import KMeans\n",
      "from sklearn.datasets import load_digits\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.preprocessing import scale\n",
      "\n",
      "np.random.seed(42)\n",
      "\n",
      "mat=scipy.io.loadmat('../data/mnist_cnn_1.mat')\n",
      "train_x=mat['seqx'];\n",
      "train_y=np.ravel(mat['seqy']);\n",
      "data = scale(train_x)\n",
      "n_samples, n_features = data.shape\n",
      "n_digits = len(np.unique(digits.target))\n",
      "labels = train_y\n",
      "\n",
      "sample_size = 300\n",
      "\n",
      "print(\"n_digits: %d, \\t n_samples %d, \\t n_features %d\"\n",
      "      % (n_digits, n_samples, n_features))\n",
      "\n",
      "\n",
      "print(79 * '_')\n",
      "print('% 9s' % 'init'\n",
      "      '    time  inertia    homo   compl  v-meas     ARI AMI  silhouette')\n",
      "\n",
      "\n",
      "def bench_k_means(estimator, name, data):\n",
      "    t0 = time()\n",
      "    estimator.fit(data)\n",
      "    print('% 9s   %.2fs    %i   %.3f   %.3f   %.3f   %.3f   %.3f    %.3f'\n",
      "          % (name, (time() - t0), estimator.inertia_,\n",
      "             metrics.homogeneity_score(labels, estimator.labels_),\n",
      "             metrics.completeness_score(labels, estimator.labels_),\n",
      "             metrics.v_measure_score(labels, estimator.labels_),\n",
      "             metrics.adjusted_rand_score(labels, estimator.labels_),\n",
      "             metrics.adjusted_mutual_info_score(labels,  estimator.labels_),\n",
      "             metrics.silhouette_score(data, estimator.labels_,\n",
      "                                      metric='euclidean',\n",
      "                                      sample_size=sample_size)))\n",
      "\n",
      "bench_k_means(KMeans(init='k-means++', n_clusters=n_digits, n_init=10),\n",
      "              name=\"k-means++\", data=data)\n",
      "\n",
      "bench_k_means(KMeans(init='random', n_clusters=n_digits, n_init=10),\n",
      "              name=\"random\", data=data)\n",
      "\n",
      "# in this case the seeding of the centers is deterministic, hence we run the\n",
      "# kmeans algorithm only once with n_init=1\n",
      "pca = PCA(n_components=n_digits).fit(data)\n",
      "bench_k_means(KMeans(init=pca.components_, n_clusters=n_digits, n_init=1),\n",
      "              name=\"PCA-based\",\n",
      "              data=data)\n",
      "print(79 * '_')\n",
      "\n",
      "###############################################################################\n",
      "# Visualize the results on PCA-reduced data\n",
      "\n",
      "reduced_data = PCA(n_components=2).fit_transform(data)\n",
      "kmeans = KMeans(init='k-means++', n_clusters=n_digits, n_init=10)\n",
      "kmeans.fit(reduced_data)\n",
      "\n",
      "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
      "h = .02     # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
      "\n",
      "# Plot the decision boundary. For that, we will assign a color to each\n",
      "x_min, x_max = reduced_data[:, 0].min() + 1, reduced_data[:, 0].max() - 1\n",
      "y_min, y_max = reduced_data[:, 1].min() + 1, reduced_data[:, 1].max() - 1\n",
      "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
      "\n",
      "# Obtain labels for each point in mesh. Use last trained model.\n",
      "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
      "\n",
      "# Put the result into a color plot\n",
      "Z = Z.reshape(xx.shape)\n",
      "pl.figure(1)\n",
      "pl.clf()\n",
      "pl.imshow(Z, interpolation='nearest',\n",
      "          extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
      "          cmap=pl.cm.Paired,\n",
      "          aspect='auto', origin='lower')\n",
      "\n",
      "pl.plot(reduced_data[:, 0], reduced_data[:, 1], 'k.', markersize=2)\n",
      "# Plot the centroids as a white X\n",
      "centroids = kmeans.cluster_centers_\n",
      "pl.scatter(centroids[:, 0], centroids[:, 1],\n",
      "           marker='x', s=169, linewidths=3,\n",
      "           color='w', zorder=10)\n",
      "pl.title('K-means clustering on the digits dataset (PCA-reduced data)\\n'\n",
      "         'Centroids are marked with white cross')\n",
      "pl.xlim(x_min, x_max)\n",
      "pl.ylim(y_min, y_max)\n",
      "pl.xticks(())\n",
      "pl.yticks(())\n",
      "pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Automatically created module for IPython interactive environment\n",
        "n_digits: 10, \t n_samples 10000, \t n_features 192"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "_______________________________________________________________________________\n",
        "init    time  inertia    homo   compl  v-meas     ARI AMI  silhouette\n",
        "k-means++   9.03s    987195   0.505   0.509   0.507   0.393   0.504    0.176"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "   random   7.42s    987194   0.505   0.509   0.507   0.393   0.504    0.153"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "PCA-based   1.42s    995093   0.487   0.493   0.490   0.374   0.486    0.159"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
      "clf = NearestCentroid()\n",
      "scores = cross_validation.cross_val_score(clf, train_x, train_y, cv=2)\n",
      "print scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from time import time\n",
      "import numpy as np\n",
      "import pylab as pl\n",
      "import scipy.io\n",
      "from sklearn import metrics\n",
      "from sklearn.cluster import KMeans\n",
      "from sklearn.datasets import load_digits\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.preprocessing import scale\n",
      "\n",
      "np.random.seed(42)\n",
      "\n",
      "mat=scipy.io.loadmat('../data/mnist_cnn_4.mat')\n",
      "train_x=mat['seqx'];\n",
      "train_y=np.ravel(mat['seqy']);\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
      "clf = NearestCentroid()\n",
      "scores = cross_validation.cross_val_score(clf, train_x, train_y, cv=5)\n",
      "print scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.86275  0.872    0.8705   0.8765   0.8705 ]\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}